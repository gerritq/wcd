{
  "model_type": "slm",
  "model_name": "meta-llama/Llama-3.1-8B-Instruct",
  "atl": true,
  "context": true,
  "smoke_test": false,
  "training_size": 50,
  "experiment": "cl_eval",
  "prompt_template": "instruct",
  "epochs": 1,
  "learning_rate": 0.0002,
  "batch_size": 16,
  "max_grad_norm": 1.0,
  "weight_decay": 0.01,
  "quantization": true,
  "max_length": 512,
  "metric": "f1",
  "lang_setting": "main",
  "lang": "ro",
  "train_log_step": 20,
  "source_langs": [
    "en"
  ],
  "target_langs": [
    "uk",
    "ro",
    "id",
    "bg",
    "uz"
  ],
  "lang_settings": [
    "main",
    "translation"
  ],
  "cl_settings": [
    "zero",
    "few"
  ],
  "seeds": [
    "42"
  ],
  "from_checkpoint": true,
  "save_checkpoint": false,
  "lower_lr": false,
  "cl_setting": "few",
  "seed": 42,
  "model_dir": "/scratch/prj/inf_nlg_ai_detection/wcd/data/exp2/models/run_nlt67xo6",
  "run_dir": "/scratch/prj/inf_nlg_ai_detection/wcd/data/exp2/eval/ro/run_lobw75_4",
  "label_dist": {
    "train": {
      "0": 25,
      "1": 24
    },
    "dev": {
      "0": 250,
      "1": 249
    },
    "test": {
      "0": 249,
      "1": 247
    }
  },
  "date": "2025-12-23T13:55:13.232734",
  "duration": 2,
  "max_memory": 28.855260372161865,
  "bf16": true,
  "train_loss": [
    {
      "epoch": 1,
      "batch": 0,
      "loss": 0.11034129559993744
    }
  ],
  "dev_loss": [
    {
      "epoch": 1,
      "batch": 0,
      "loss": 0.1397
    }
  ],
  "dev_metrics": [
    {
      "epoch": 1,
      "metrics": {
        "accuracy": 0.5551102204408818,
        "f1": 0.5842696629213483,
        "tp": 156,
        "fp": 129,
        "tn": 121,
        "fn": 93,
        "n_valid": 499,
        "n_total": 499
      }
    }
  ],
  "test_metrics": [
    {
      "epoch": 1,
      "metrics": {
        "accuracy": 0.6189516129032258,
        "f1": 0.6227544910179641,
        "tp": 156,
        "fp": 98,
        "tn": 151,
        "fn": 91,
        "n_valid": 496,
        "n_total": 496
      }
    }
  ]
}