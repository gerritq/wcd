{
  "model_type": "slm",
  "model_name": "CohereLabs/aya-expanse-8b",
  "atl": false,
  "context": true,
  "smoke_test": false,
  "training_size": 5000,
  "experiment": "binary",
  "prompt_template": "instruct",
  "epochs": 4,
  "learning_rate": 5e-05,
  "batch_size": 16,
  "max_grad_norm": 1.0,
  "weight_decay": 0.01,
  "quantization": true,
  "lang": "nl",
  "run_dir": "/scratch/prj/inf_nlg_ai_detection/wcd/data/exp1/nl/run_KiNeva",
  "notes": "testing 1 grad norm",
  "train_log_step": 20,
  "prompt_extension": "",
  "max_length": 512,
  "seed": 42,
  "training_langs": [],
  "test_lang": "",
  "model_dir": "",
  "save_checkpoint": false,
  "from_checkpoint": false,
  "label_dist": {
    "train": {
      "0": 2500,
      "1": 2500
    },
    "dev": {
      "0": 250,
      "1": 249
    },
    "test": {
      "0": 249,
      "1": 250
    }
  },
  "date": "2025-12-13T09:30:32.213259",
  "duration": 48,
  "max_memory": 36.914169788360596,
  "bf16": true,
  "train_loss": [
    {
      "epoch": 1,
      "batch": 0,
      "loss": 15.519294738769531
    },
    {
      "epoch": 1,
      "batch": 20,
      "loss": 12.620796203613281
    },
    {
      "epoch": 1,
      "batch": 40,
      "loss": 7.629708290100098
    },
    {
      "epoch": 1,
      "batch": 60,
      "loss": 6.645544052124023
    },
    {
      "epoch": 1,
      "batch": 80,
      "loss": 6.049644470214844
    },
    {
      "epoch": 1,
      "batch": 100,
      "loss": 5.8138203620910645
    },
    {
      "epoch": 1,
      "batch": 120,
      "loss": 5.762668609619141
    },
    {
      "epoch": 1,
      "batch": 140,
      "loss": 5.8273749351501465
    },
    {
      "epoch": 1,
      "batch": 160,
      "loss": 5.593695163726807
    },
    {
      "epoch": 1,
      "batch": 180,
      "loss": 5.845358848571777
    },
    {
      "epoch": 1,
      "batch": 200,
      "loss": 5.605085372924805
    },
    {
      "epoch": 1,
      "batch": 220,
      "loss": 5.849181175231934
    },
    {
      "epoch": 1,
      "batch": 240,
      "loss": 5.688825607299805
    },
    {
      "epoch": 1,
      "batch": 260,
      "loss": 6.027031898498535
    },
    {
      "epoch": 1,
      "batch": 280,
      "loss": 5.849366188049316
    },
    {
      "epoch": 1,
      "batch": 300,
      "loss": 5.608885288238525
    },
    {
      "epoch": 2,
      "batch": 0,
      "loss": 5.786488056182861
    },
    {
      "epoch": 2,
      "batch": 20,
      "loss": 5.589139938354492
    },
    {
      "epoch": 2,
      "batch": 40,
      "loss": 5.712009429931641
    },
    {
      "epoch": 2,
      "batch": 60,
      "loss": 5.686420917510986
    },
    {
      "epoch": 2,
      "batch": 80,
      "loss": 5.6595778465271
    },
    {
      "epoch": 2,
      "batch": 100,
      "loss": 5.544368267059326
    },
    {
      "epoch": 2,
      "batch": 120,
      "loss": 5.542145729064941
    },
    {
      "epoch": 2,
      "batch": 140,
      "loss": 5.529965877532959
    },
    {
      "epoch": 2,
      "batch": 160,
      "loss": 5.58673095703125
    },
    {
      "epoch": 2,
      "batch": 180,
      "loss": 5.816445350646973
    },
    {
      "epoch": 2,
      "batch": 200,
      "loss": 5.922788619995117
    },
    {
      "epoch": 2,
      "batch": 220,
      "loss": 5.439990043640137
    },
    {
      "epoch": 2,
      "batch": 240,
      "loss": 5.969600677490234
    },
    {
      "epoch": 2,
      "batch": 260,
      "loss": 5.577047348022461
    },
    {
      "epoch": 2,
      "batch": 280,
      "loss": 5.537847995758057
    },
    {
      "epoch": 2,
      "batch": 300,
      "loss": 5.818223476409912
    },
    {
      "epoch": 3,
      "batch": 0,
      "loss": 5.638858795166016
    },
    {
      "epoch": 3,
      "batch": 20,
      "loss": 5.607264518737793
    },
    {
      "epoch": 3,
      "batch": 40,
      "loss": 5.90836238861084
    },
    {
      "epoch": 3,
      "batch": 60,
      "loss": 5.767452239990234
    },
    {
      "epoch": 3,
      "batch": 80,
      "loss": 5.962245941162109
    },
    {
      "epoch": 3,
      "batch": 100,
      "loss": 5.50126838684082
    },
    {
      "epoch": 3,
      "batch": 120,
      "loss": 5.693121910095215
    },
    {
      "epoch": 3,
      "batch": 140,
      "loss": 5.602324962615967
    },
    {
      "epoch": 3,
      "batch": 160,
      "loss": 5.757489204406738
    },
    {
      "epoch": 3,
      "batch": 180,
      "loss": 5.623925685882568
    },
    {
      "epoch": 3,
      "batch": 200,
      "loss": 5.460292816162109
    },
    {
      "epoch": 3,
      "batch": 220,
      "loss": 5.606428623199463
    },
    {
      "epoch": 3,
      "batch": 240,
      "loss": 5.575279235839844
    },
    {
      "epoch": 3,
      "batch": 260,
      "loss": 5.347370147705078
    },
    {
      "epoch": 3,
      "batch": 280,
      "loss": 5.924697399139404
    },
    {
      "epoch": 3,
      "batch": 300,
      "loss": 5.3923845291137695
    },
    {
      "epoch": 4,
      "batch": 0,
      "loss": 5.580515384674072
    },
    {
      "epoch": 4,
      "batch": 20,
      "loss": 5.668909072875977
    },
    {
      "epoch": 4,
      "batch": 40,
      "loss": 5.569657325744629
    },
    {
      "epoch": 4,
      "batch": 60,
      "loss": 5.734549522399902
    },
    {
      "epoch": 4,
      "batch": 80,
      "loss": 5.453759670257568
    },
    {
      "epoch": 4,
      "batch": 100,
      "loss": 5.433524131774902
    },
    {
      "epoch": 4,
      "batch": 120,
      "loss": 5.8935723304748535
    },
    {
      "epoch": 4,
      "batch": 140,
      "loss": 5.636202812194824
    },
    {
      "epoch": 4,
      "batch": 160,
      "loss": 5.514824867248535
    },
    {
      "epoch": 4,
      "batch": 180,
      "loss": 5.313945770263672
    },
    {
      "epoch": 4,
      "batch": 200,
      "loss": 5.612405300140381
    },
    {
      "epoch": 4,
      "batch": 220,
      "loss": 5.540618896484375
    },
    {
      "epoch": 4,
      "batch": 240,
      "loss": 5.571689128875732
    },
    {
      "epoch": 4,
      "batch": 260,
      "loss": 5.63945198059082
    },
    {
      "epoch": 4,
      "batch": 280,
      "loss": 5.73594856262207
    },
    {
      "epoch": 4,
      "batch": 300,
      "loss": 5.991294860839844
    }
  ],
  "dev_loss": [
    {
      "epoch": 1,
      "batch": 0,
      "loss": 16.3169
    },
    {
      "epoch": 1,
      "batch": 60,
      "loss": 6.3755
    },
    {
      "epoch": 1,
      "batch": 120,
      "loss": 5.852
    },
    {
      "epoch": 1,
      "batch": 180,
      "loss": 5.7872
    },
    {
      "epoch": 1,
      "batch": 240,
      "loss": 5.7238
    },
    {
      "epoch": 1,
      "batch": 300,
      "loss": 5.7151
    },
    {
      "epoch": 2,
      "batch": 0,
      "loss": 5.6992
    },
    {
      "epoch": 2,
      "batch": 60,
      "loss": 5.7175
    },
    {
      "epoch": 2,
      "batch": 120,
      "loss": 5.6734
    },
    {
      "epoch": 2,
      "batch": 180,
      "loss": 5.661
    },
    {
      "epoch": 2,
      "batch": 240,
      "loss": 5.6583
    },
    {
      "epoch": 2,
      "batch": 300,
      "loss": 5.6477
    },
    {
      "epoch": 3,
      "batch": 0,
      "loss": 5.6407
    },
    {
      "epoch": 3,
      "batch": 60,
      "loss": 5.6428
    },
    {
      "epoch": 3,
      "batch": 120,
      "loss": 5.6306
    },
    {
      "epoch": 3,
      "batch": 180,
      "loss": 5.631
    },
    {
      "epoch": 3,
      "batch": 240,
      "loss": 5.6278
    },
    {
      "epoch": 3,
      "batch": 300,
      "loss": 5.621
    },
    {
      "epoch": 4,
      "batch": 0,
      "loss": 5.6199
    },
    {
      "epoch": 4,
      "batch": 60,
      "loss": 5.6304
    },
    {
      "epoch": 4,
      "batch": 120,
      "loss": 5.6146
    },
    {
      "epoch": 4,
      "batch": 180,
      "loss": 5.6158
    },
    {
      "epoch": 4,
      "batch": 240,
      "loss": 5.6145
    },
    {
      "epoch": 4,
      "batch": 300,
      "loss": 5.6149
    }
  ],
  "dev_metrics": [
    {
      "epoch": 1,
      "metrics": {
        "accuracy": 0.48893360160965793,
        "f1": 0.60062893081761,
        "tp": 191,
        "fp": 197,
        "tn": 52,
        "fn": 57,
        "n_valid": 497,
        "n_total": 499
      }
    },
    {
      "epoch": 2,
      "metrics": {
        "accuracy": 0.4919678714859438,
        "f1": 0.4511930585683297,
        "tp": 104,
        "fp": 109,
        "tn": 141,
        "fn": 144,
        "n_valid": 498,
        "n_total": 499
      }
    },
    {
      "epoch": 3,
      "metrics": {
        "accuracy": 0.5,
        "f1": 0.4230769230769231,
        "tp": 88,
        "fp": 88,
        "tn": 152,
        "fn": 152,
        "n_valid": 480,
        "n_total": 499
      }
    },
    {
      "epoch": 4,
      "metrics": {
        "accuracy": 0.512396694214876,
        "f1": 0.5613382899628253,
        "tp": 151,
        "fp": 143,
        "tn": 97,
        "fn": 93,
        "n_valid": 484,
        "n_total": 499
      }
    }
  ],
  "test_metrics": [
    {
      "epoch": 1,
      "metrics": {
        "accuracy": 0.5210420841683366,
        "f1": 0.6271450858034321,
        "tp": 201,
        "fp": 190,
        "tn": 59,
        "fn": 49,
        "n_valid": 499,
        "n_total": 499
      }
    },
    {
      "epoch": 2,
      "metrics": {
        "accuracy": 0.5070140280561122,
        "f1": 0.4896265560165975,
        "tp": 118,
        "fp": 114,
        "tn": 135,
        "fn": 132,
        "n_valid": 499,
        "n_total": 499
      }
    },
    {
      "epoch": 3,
      "metrics": {
        "accuracy": 0.5031446540880503,
        "f1": 0.4397163120567376,
        "tp": 93,
        "fp": 89,
        "tn": 147,
        "fn": 148,
        "n_valid": 477,
        "n_total": 499
      }
    },
    {
      "epoch": 4,
      "metrics": {
        "accuracy": 0.5040983606557377,
        "f1": 0.5518518518518518,
        "tp": 149,
        "fp": 145,
        "tn": 97,
        "fn": 97,
        "n_valid": 488,
        "n_total": 499
      }
    }
  ]
}