{
  "model_type": "plm",
  "model_name": "FacebookAI/xlm-roberta-large",
  "atl": false,
  "context": true,
  "smoke_test": false,
  "training_size": 5000,
  "experiment": "seed",
  "prompt_template": "instruct",
  "epochs": 2,
  "learning_rate": 1e-05,
  "batch_size": 32,
  "max_grad_norm": 1.0,
  "weight_decay": 0.01,
  "quantization": true,
  "lang": "sq",
  "run_dir": "/scratch/prj/inf_nlg_ai_detection/wcd/data/exp1/sq/run_wLzrTo",
  "model_dir": "",
  "notes": "",
  "train_log_step": 20,
  "prompt_extension": "",
  "max_length": 512,
  "seed": 2025,
  "metric": "f1",
  "setting": "main",
  "lang_setting": "main",
  "source_langs": [],
  "target_langs": [],
  "lang_settings": [],
  "cl_settings": [],
  "save_checkpoint": false,
  "from_checkpoint": false,
  "label_dist": {
    "train": {
      "0": 2468,
      "1": 2457
    },
    "dev": {
      "0": 250,
      "1": 250
    },
    "test": {
      "0": 250,
      "1": 250
    }
  },
  "date": "2025-12-22T16:51:56.352007",
  "duration": 1,
  "max_memory": 10.416999340057373,
  "bf16": true,
  "train_loss": [
    {
      "epoch": 1,
      "batch": 0,
      "loss": 0.72052001953125
    },
    {
      "epoch": 1,
      "batch": 20,
      "loss": 0.73907470703125
    },
    {
      "epoch": 1,
      "batch": 40,
      "loss": 0.725341796875
    },
    {
      "epoch": 1,
      "batch": 60,
      "loss": 0.6986083984375
    },
    {
      "epoch": 1,
      "batch": 80,
      "loss": 0.67236328125
    },
    {
      "epoch": 1,
      "batch": 100,
      "loss": 0.65411376953125
    },
    {
      "epoch": 1,
      "batch": 120,
      "loss": 0.66448974609375
    },
    {
      "epoch": 1,
      "batch": 140,
      "loss": 0.6346435546875
    },
    {
      "epoch": 2,
      "batch": 0,
      "loss": 0.68377685546875
    },
    {
      "epoch": 2,
      "batch": 20,
      "loss": 0.7352294921875
    },
    {
      "epoch": 2,
      "batch": 40,
      "loss": 0.64630126953125
    },
    {
      "epoch": 2,
      "batch": 60,
      "loss": 0.66973876953125
    },
    {
      "epoch": 2,
      "batch": 80,
      "loss": 0.66094970703125
    },
    {
      "epoch": 2,
      "batch": 100,
      "loss": 0.64788818359375
    },
    {
      "epoch": 2,
      "batch": 120,
      "loss": 0.64794921875
    },
    {
      "epoch": 2,
      "batch": 140,
      "loss": 0.6612548828125
    }
  ],
  "dev_loss": [
    {
      "epoch": 1,
      "batch": 0,
      "loss": 0.7703
    },
    {
      "epoch": 1,
      "batch": 60,
      "loss": 0.6885
    },
    {
      "epoch": 1,
      "batch": 120,
      "loss": 0.669
    },
    {
      "epoch": 2,
      "batch": 0,
      "loss": 0.6644
    },
    {
      "epoch": 2,
      "batch": 60,
      "loss": 0.6616
    },
    {
      "epoch": 2,
      "batch": 120,
      "loss": 0.6589
    }
  ],
  "dev_metrics": [
    {
      "epoch": 1,
      "metrics": {
        "accuracy": 0.594,
        "f1": 0.6219739292364991,
        "tp": 167,
        "fp": 120,
        "tn": 130,
        "fn": 83,
        "n_total": 500
      }
    },
    {
      "epoch": 2,
      "metrics": {
        "accuracy": 0.648,
        "f1": 0.6465863453815262,
        "tp": 161,
        "fp": 87,
        "tn": 163,
        "fn": 89,
        "n_total": 500
      }
    }
  ],
  "test_metrics": [
    {
      "epoch": 1,
      "metrics": {
        "accuracy": 0.646,
        "f1": 0.6716141001855288,
        "tp": 181,
        "fp": 108,
        "tn": 142,
        "fn": 69,
        "n_total": 500
      }
    },
    {
      "epoch": 2,
      "metrics": {
        "accuracy": 0.654,
        "f1": 0.6533066132264529,
        "tp": 163,
        "fp": 86,
        "tn": 164,
        "fn": 87,
        "n_total": 500
      }
    }
  ]
}