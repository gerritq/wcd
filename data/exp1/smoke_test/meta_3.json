{
  "model_type": "slm",
  "model_name": "meta-llama/Llama-3.1-8B-Instruct",
  "atl": false,
  "context": true,
  "smoke_test": true,
  "training_size": 5000,
  "experiment": "seed",
  "prompt_template": "instruct",
  "epochs": 1,
  "learning_rate": 0.0005,
  "batch_size": 16,
  "max_grad_norm": 1.0,
  "weight_decay": 0.01,
  "quantization": true,
  "lang": "en",
  "run_dir": "",
  "notes": "",
  "train_log_step": 20,
  "prompt_extension": "",
  "max_length": 512,
  "seed": 2025,
  "metric": "f1",
  "training_langs": [],
  "test_lang": "",
  "model_dir": "",
  "save_checkpoint": false,
  "from_checkpoint": false,
  "label_dist": {
    "train": {
      "0": 2499,
      "1": 2497
    },
    "dev": {
      "0": 250,
      "1": 250
    },
    "test": {
      "0": 250,
      "1": 249
    }
  },
  "date": "2025-12-19T17:51:42.807276",
  "duration": 0,
  "max_memory": 17.510314464569092,
  "bf16": true,
  "train_loss": [
    {
      "epoch": 1,
      "batch": 0,
      "loss": 3.5883564949035645
    }
  ],
  "dev_loss": [
    {
      "epoch": 1,
      "batch": 0,
      "loss": 2.6479
    }
  ],
  "dev_metrics": [
    {
      "epoch": 1,
      "metrics": {
        "accuracy": 0.53125,
        "f1": 0.5714285714285714,
        "tp": 10,
        "fp": 7,
        "tn": 7,
        "fn": 8,
        "n_valid": 32,
        "n_total": 32
      }
    }
  ],
  "test_metrics": [
    {
      "epoch": 1,
      "metrics": {
        "accuracy": 0.65625,
        "f1": 0.6857142857142857,
        "tp": 12,
        "fp": 8,
        "tn": 9,
        "fn": 3,
        "n_valid": 32,
        "n_total": 32
      }
    }
  ]
}