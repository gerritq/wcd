

\begin{tabular}{lccccccccccccc}
\hline
\textbf{Model} $\downarrow$\ \textbf{Language} $\rightarrow$ & \textbf{en} & \textbf{nl} & \textbf{no} & \textbf{it} & \textbf{pt} & \textbf{ro} & \textbf{ru} & \textbf{uk} & \textbf{bg} & \textbf{vi} & \textbf{id} & \textbf{tr} & \textbf{Avg} \\
\hline
XLM-R-base & -- & -- & -- & -- & -- & -- & -- & -- & 0.495 & \underline{0.646} & -- & \textbf{0.695} & 0.612 \\
XLM-R-large & -- & -- & \textbf{0.640} & -- & -- & \underline{0.650} & -- & -- & \underline{0.527} & -- & -- & \underline{0.667} & 0.621 \\
mBert & -- & -- & -- & -- & -- & \textbf{0.655} & -- & \underline{0.631} & \textbf{0.560} & -- & -- & \underline{0.667} & 0.628 \\
mDeberta-base & -- & -- & -- & -- & -- & -- & -- & -- & 0.500 & -- & -- & -- & 0.500 \\
mDeberta-large & \textbf{0.892} & -- & -- & -- & -- & -- & -- & \textbf{0.681} & -- & \textbf{0.701} & -- & -- & \textbf{0.758} \\
\hline
\rowcolor{lightgray}\multicolumn{14}{c}{\textbf{Decoder-based SLMs}} \\
\hline
Llama3-8B (van) & -- & \textbf{0.623} & -- & \underline{0.650} & -- & -- & -- & -- & -- & -- & -- & -- & 0.636 \\
Llama3-8B (atl) & -- & \underline{0.560} & -- & \textbf{0.666} & -- & -- & -- & -- & -- & -- & \textbf{0.725} & -- & \underline{0.650} \\
\hline
\end{tabular}
